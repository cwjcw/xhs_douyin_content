import read_sql as rs
import os
import re
import sys
import jdy
import pandas as pd
import asyncio
from datetime import datetime, timedelta

# é…ç½®æ¨¡å—çº§è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, ".."))
if project_root not in sys.path:
    sys.path.append(project_root)

from project_config.project import xhs_custom_count_sql
from data_processing.xhs_video_analysis import DailyDataProcessor

class Dividend:
    """
    è§†é¢‘å†…å®¹åˆ†çº¢ç®¡ç†ç±»ï¼šç”¨äºè¯»å–è§†é¢‘æ•°æ®ã€å®¢èµ„æ•°æ®å’Œç®€é“äº‘ä¿¡æ¯ï¼Œ
    è¿›è¡Œå†…å®¹è¡¨ç°åˆ†æã€åˆ†çº¢è®¡ç®—å¹¶å¯ä¸Šä¼ ç»“æœè‡³ç®€é“äº‘ã€‚
    """

    def __init__(self):
        self.sql = rs.MSSQLDatabase()
        self.custom_count_path = xhs_custom_count_sql
        self.jdy = jdy.JDY()
        self.daily_process = DailyDataProcessor()
        self.metrics = ['è§‚çœ‹é‡', 'ç‚¹èµ', 'æ”¶è—', 'è¯„è®º', 'åˆ†äº«']
        self._cached_jdy_data = None

    def get_jdy_data_cached(self):
        """
        ä»ç®€é“äº‘è·å–å¹¶ç¼“å­˜æ•°æ®ï¼Œé¿å…é‡å¤è°ƒç”¨ã€‚
        """
        if self._cached_jdy_data is None:
            appId = "67c280b7c6387c4f4afd50ae"
            entryId = "67c2816ffa795e84a8fe45b9"
            self._cached_jdy_data = self.jdy.get_jdy_data(app_id=appId, entry_id=entryId)
        return self._cached_jdy_data

    def get_custom_count(self):
        """
        ä»SQLæ–‡ä»¶è¯»å–å®¢èµ„æ•°é‡ã€‚
        """
        try:
            return self.sql.get_from_sqlfile(self.custom_count_path)
        except Exception as e:
            print(f"è¯»å–å®¢èµ„æ•°å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_daily_video_data(self):
        """
        è·å–æ¯æ—¥è§†é¢‘æ•°æ®ï¼Œå­—æ®µè‡ªåŠ¨æ ‡å‡†åŒ–ã€‚
        """
        try:
            df = self.daily_process.get_daily_data()
            rename_map = {
                'æ’­æ”¾é‡': 'è§‚çœ‹é‡',
                'æ’­æ”¾æ¬¡æ•°': 'è§‚çœ‹é‡'
            }
            df.rename(columns=rename_map, inplace=True)
            return df
        except Exception as e:
            print("âŒ get_daily_data æŠ¥é”™ï¼š", e)
            return pd.DataFrame()

    def video_dividend(self):
        """
        è®¡ç®—æ¯æ¡è§†é¢‘æ ¹æ®è¡¨ç°åº”å¾—çš„åˆ†æˆé‡‘é¢ã€‚
        è¿”å›åŒ…å« [ä½œå“åç§°, æ€»åˆ†æˆ, æ—¥æœŸ] çš„ DataFrameã€‚
        """
        video_df = self.get_daily_video_data()
        print("ğŸ¬ video_df å­—æ®µåï¼š", video_df.columns.tolist())

        jdy_data = self.get_jdy_data_cached()
        content_df = pd.DataFrame(jdy_data)
        print("ğŸ“„ content_df å­—æ®µåï¼š", content_df.columns.tolist())

        content_df['æ­£ç‰‡æ ‡é¢˜'] = content_df['_widget_1740646149825'].astype(str).apply(lambda x: re.sub(r'\s*#.*', '', x))
        video_df['ç¬”è®°æ ‡é¢˜'] = video_df['ç¬”è®°æ ‡é¢˜'].astype(str).apply(lambda x: re.sub(r'\s*#.*', '', x))

        merged_df = content_df.merge(video_df, left_on='æ­£ç‰‡æ ‡é¢˜', right_on='ç¬”è®°æ ‡é¢˜', how='left')
        print("ğŸ§© merged_df å­—æ®µåï¼š", merged_df.columns.tolist())

        for metric in self.metrics:
            if metric not in merged_df.columns:
                print(f"âš ï¸ ç¼ºå¤±å­—æ®µ {metric}ï¼Œè‡ªåŠ¨å¡«å…… 0")
                merged_df[metric] = 0

        metric_weights = {
            'è§‚çœ‹é‡': 0.05,
            'ç‚¹èµ': 0.05,
            'æ”¶è—': 0.3,
            'è¯„è®º': 0.3,
            'åˆ†äº«': 0.3
        }

        for metric, weight in metric_weights.items():
            max_val = merged_df[metric].max()
            merged_df[f'{metric}_æ ‡å‡†åŒ–'] = merged_df[metric].apply(lambda x: (x / max_val) * weight if max_val > 0 else 0)

        merged_df['æ€»è¡¨ç°åˆ†'] = merged_df[[f'{m}_æ ‡å‡†åŒ–' for m in metric_weights]].sum(axis=1)
        video_scores = merged_df.groupby('æ­£ç‰‡æ ‡é¢˜', as_index=False)['æ€»è¡¨ç°åˆ†'].sum()
        video_scores = video_scores[video_scores['æ€»è¡¨ç°åˆ†'] > 0]

        total_money = self.total_money_dy()
        total_customers = total_money // 50
        total_scores = video_scores['æ€»è¡¨ç°åˆ†'].sum()
        video_scores['å®¢æˆ·æ•°'] = ((video_scores['æ€»è¡¨ç°åˆ†'] / total_scores) * total_customers).round().astype(int)

        diff = total_customers - video_scores['å®¢æˆ·æ•°'].sum()
        if diff != 0:
            idx = video_scores['æ€»è¡¨ç°åˆ†'].idxmax()
            video_scores.at[idx, 'å®¢æˆ·æ•°'] += diff

        video_scores['æ€»åˆ†æˆ'] = video_scores['å®¢æˆ·æ•°'] * 50
        video_scores['æ—¥æœŸ'] = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        video_scores.rename(columns={'æ­£ç‰‡æ ‡é¢˜': 'ä½œå“åç§°'}, inplace=True)
        return video_scores[['ä½œå“åç§°', 'æ€»åˆ†æˆ', 'æ—¥æœŸ']]

    def total_money_dy(self):
        """
        æ€»åˆ†çº¢æ± é‡‘é¢ï¼ˆ= å®¢èµ„æ€»æ•° Ã— 50ï¼‰ã€‚
        """
        df = self.get_custom_count()
        return df['å®¢èµ„æ•°'].sum() * 50 if 'å®¢èµ„æ•°' in df.columns else 0

    def get_video_people(self):
        """
        è·å–è§†é¢‘äººå‘˜å‚ä¸ä¿¡æ¯ï¼Œè¿”å›æ¯æ¡è§†é¢‘å¯¹åº”äººå‘˜åŠè§’è‰²ã€‚
        """
        jdy_data = self.get_jdy_data_cached()
        rows = []
        for doc in jdy_data:
            title_raw = doc.get("_widget_1740646149825", "")
            title_cleaned = re.sub(r'\s*#.*', '', title_raw)
            base_fields = {
                "è´¦å·åç§°": doc.get("_widget_1741257105163", ""),
                "è´¦å·ID": doc.get("_widget_1741257105165", ""),
                "æ˜¯å¦å®Œæ•´å†…å®¹": doc.get("_widget_1740798082550", ""),
                "æ­£ç‰‡æ ‡é¢˜": title_cleaned,
                "æäº¤æ—¥æœŸ": doc.get("_widget_1740646149826", ""),
                "æ¥æºé—¨åº—/éƒ¨é—¨": doc.get("_widget_1741934971937", {}).get("name", "")
            }
            user_groups = {
                "å®Œæ•´å†…å®¹æä¾›": [u.get("username") for u in doc.get("_widget_1740798082567", [])],
                "åŠæˆå“å†…å®¹æä¾›": [u.get("username") for u in doc.get("_widget_1740798082568", [])],
                "å‰ªè¾‘": [u.get("username") for u in doc.get("_widget_1740798082569", [])],
                "å‘å¸ƒè¿è¥": [u.get("username") for u in doc.get("_widget_1740798082570", [])]
            }
            max_len = max(len(g) for g in user_groups.values()) or 1
            aligned_groups = {}
            for field, users in user_groups.items():
                aligned_groups[field] = users + [None] * (max_len - len(users))
            row = {**base_fields, **aligned_groups}
            rows.append(row)

        df = pd.DataFrame(rows)
        exploded_dfs = []
        for group in ["å®Œæ•´å†…å®¹æä¾›", "åŠæˆå“å†…å®¹æä¾›", "å‰ªè¾‘", "å‘å¸ƒè¿è¥"]:
            temp_df = df[["æ­£ç‰‡æ ‡é¢˜", group]].explode(group)
            temp_df = temp_df.rename(columns={group: "äººå‘˜"})
            temp_df["äººå‘˜ç±»åˆ«"] = group
            exploded_dfs.append(temp_df)

        final_df = pd.concat(exploded_dfs, ignore_index=True)
        base_df = df[["æ­£ç‰‡æ ‡é¢˜", "è´¦å·åç§°", "è´¦å·ID", "æ˜¯å¦å®Œæ•´å†…å®¹", "æäº¤æ—¥æœŸ", "æ¥æºé—¨åº—/éƒ¨é—¨"]]
        final_df = final_df.merge(base_df, on="æ­£ç‰‡æ ‡é¢˜", how="left")
        final_df = final_df.dropna(subset=["äººå‘˜"])

        return final_df[["æ­£ç‰‡æ ‡é¢˜", "è´¦å·åç§°", "è´¦å·ID", "æ˜¯å¦å®Œæ•´å†…å®¹", "äººå‘˜ç±»åˆ«", "äººå‘˜", "æäº¤æ—¥æœŸ", "æ¥æºé—¨åº—/éƒ¨é—¨"]].reset_index(drop=True)

    def everyone_money(self):
        """
        æ ¹æ®å‚ä¸äººåŠè§’è‰²è®¡ç®—æ¯äººåº”å¾—çš„åˆ†çº¢é‡‘é¢ã€‚
        """
        video_people = self.get_video_people()
        video_money = self.video_dividend()
        video_people = video_people.rename(columns={"æ­£ç‰‡æ ‡é¢˜": "ä½œå“åç§°"})
        merged = video_people.merge(video_money, on="ä½œå“åç§°", how="left")
        merged["æ€»åˆ†æˆ"] = merged["æ€»åˆ†æˆ"].fillna(0)
        total_dividend_before = video_money["æ€»åˆ†æˆ"].sum()
        print(f"ğŸ” åˆå¹¶å‰ æ€»åˆ†æˆé‡‘é¢: {total_dividend_before}")

        RULES = {
            ("æ˜¯", "å®Œæ•´å†…å®¹æä¾›"): 0.6,
            ("æ˜¯", "å‘å¸ƒè¿è¥"): 0.4,
            ("å¦", "åŠæˆå“å†…å®¹æä¾›"): 0.4,
            ("å¦", "å‰ªè¾‘"): 0.2,
            ("å¦", "å‘å¸ƒè¿è¥"): 0.4
        }
        merged["åˆ†æˆæ¯”ä¾‹"] = merged.apply(lambda row: RULES.get((row["æ˜¯å¦å®Œæ•´å†…å®¹"], row["äººå‘˜ç±»åˆ«"]), 0.2), axis=1)
        merged = merged.dropna(subset=["åˆ†æˆæ¯”ä¾‹"])
        merged["äººæ•°"] = merged.groupby(["ä½œå“åç§°", "äººå‘˜ç±»åˆ«"])["äººå‘˜"].transform("count")
        merged["åˆ†æˆé‡‘é¢"] = (merged["æ€»åˆ†æˆ"] * merged["åˆ†æˆæ¯”ä¾‹"] / merged["äººæ•°"]).round(2)

        result = merged.loc[(merged["äººå‘˜"].notnull()), ["ä½œå“åç§°", "äººå‘˜", "åˆ†æˆé‡‘é¢"]]
        total_dividend_after = result["åˆ†æˆé‡‘é¢"].sum()
        diff = round(total_dividend_before - total_dividend_after, 2)
        if diff != 0:
            idx = result["åˆ†æˆé‡‘é¢"].idxmax()
            result.loc[idx, "åˆ†æˆé‡‘é¢"] = round(result.loc[idx, "åˆ†æˆé‡‘é¢"] + diff, 2)

        total_dividend_after = result["åˆ†æˆé‡‘é¢"].sum()
        print(f"âœ… åˆ†é…å æ€»åˆ†æˆé‡‘é¢: {total_dividend_after}")
        if round(total_dividend_before, 2) != round(total_dividend_after, 2):
            print(f"âš ï¸ è­¦å‘Š: æ€»é‡‘é¢æœ‰æŸå¤±ï¼ç¼ºå°‘ {round(total_dividend_before - total_dividend_after, 2)}")

        summary = result.groupby("äººå‘˜", as_index=False)["åˆ†æˆé‡‘é¢"].sum()
        summary["æ—¥æœŸ"] = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        return summary[summary["åˆ†æˆé‡‘é¢"] > 0].reset_index(drop=True)

    def upload_to_jdy(self):
        """
        å°†åˆ†çº¢ç»“æœä¸Šä¼ è‡³ç®€é“äº‘ã€‚
        """
        appId = "67c280b7c6387c4f4afd50ae"
        entryId = "67d7097d08e5f607c4cfd028"
        final_data = self.everyone_money()
        asyncio.run(self.jdy.batch_create(app_id=appId, entry_id=entryId, source_data=final_data))

if __name__ == '__main__':
    dividend = Dividend()
    print(dividend.total_money_dy())
    print(dividend.get_custom_count()['å®¢èµ„æ•°'].sum())
    video_people = dividend.get_video_people()
    video_people.to_excel('å°çº¢ä¹¦è§†é¢‘ç®¡ç†.xlsx', index=False)
    people_money = dividend.everyone_money()
    people_money.to_excel('å°çº¢ä¹¦æ¯äººåˆ†çº¢é‡‘é¢.xlsx', index=False)
    data = dividend.video_dividend()
    data.to_excel('å°çº¢ä¹¦è§†é¢‘åˆ†çº¢.xlsx', index=False)
    # dividend.upload_to_jdy()