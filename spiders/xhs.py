import os, sys
import pickle
import time
import glob
import pandas as pd
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.edge.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.edge.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
from selenium.webdriver import ActionChains
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½• (data_processingç›®å½•)
current_dir = os.path.dirname(os.path.abspath(__file__))
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå³å½“å‰ç›®å½•çš„ä¸Šä¸€çº§ï¼‰
project_root = os.path.abspath(os.path.join(current_dir, ".."))
# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°sys.pathä¸­
if project_root not in sys.path:
    sys.path.append(project_root)
from project_config.project import xhs_cookie_list, xhs_file_path, driver_path


class Xhs:
    def __init__(self, url, cookies_file, download_path=xhs_file_path):
        self.url = url
        self.cookies_file = cookies_file
        self.data_center_url = "https://creator.xiaohongshu.com/statistics/data-analysis"
        self.download_path = download_path

        # é…ç½® Edge ä¸‹è½½è·¯å¾„
        edge_options = Options()
        prefs = {
            "download.default_directory": self.download_path,
            "download.prompt_for_download": False,
            "download.directory_upgrade": True,
            "safebrowsing.enabled": True
        }
        edge_options.add_experimental_option("prefs", prefs)

        # å½“ cookies_file ä¸ºç©ºæ—¶å¯ä»¥é€‰æ‹©ä¸åˆå§‹åŒ– driverï¼ˆä»…ç”¨äºæ•°æ®åˆå¹¶ï¼‰
        if self.cookies_file:
            print(f"ä½¿ç”¨æœ¬åœ° EdgeDriver è·¯å¾„: {driver_path}")
            self.driver = webdriver.Edge(
                service=Service(driver_path),
                options=edge_options
            )
            self.driver.maximize_window()
        else:
            self.driver = None

    def run(self):
        try:
            self.load_cookies()
            time.sleep(10)
        except Exception as e:
            print(f"â— Unknown error occurred: {str(e)}")
        finally:
            if self.driver:
                self.driver.quit()
                print("ğŸ›‘ Browser closed")
        time.sleep(5)

    def load_cookies(self):
        try:
            with open(self.cookies_file, "rb") as cookie_file:
                cookies = pickle.load(cookie_file)
                self.driver.get(self.url)
                self.driver.delete_all_cookies()
                for cookie in cookies:
                    if 'expiry' in cookie:
                        cookie['expiry'] = int(cookie['expiry'])
                    self.driver.add_cookie(cookie)
                self.driver.refresh()
                print("âœ… Cookies loaded, auto-login successful!")
                self._post_login_flow()
        except FileNotFoundError:
            self._manual_login()

    def _manual_login(self):
        print("âŒ Cookies not found, manual login required")
        self.driver.get(self.url)
        input("Please complete login and press Enter to continue...")
        self._save_cookies()
        self._post_login_flow()

    def _save_cookies(self):
        with open(self.cookies_file, "wb") as cookie_file:
            cookies = [c for c in self.driver.get_cookies() if c['name'] not in ['passport_csrf_token']]
            pickle.dump(cookies, cookie_file)
        print("âœ… Cookies saved successfully")

    def _post_login_flow(self):
        self.go_to_data_center()
        # å¯æ ¹æ®éœ€è¦è§£å¼€ä¸‹é¢è¿™äº›æ³¨é‡Š
        # self.close_all_popups()
        # self.click_tgzp_tab()
        # self.click_post_list_tab()
        # self.input_start_date()
        # self.input_end_date()
        self.click_export_data_button()

    def go_to_data_center(self):
        print("ğŸš€ Navigating to data center...")
        self.driver.get(self.data_center_url)
        self.wait_for_page_ready()

    def wait_for_page_ready(self, timeout=30):
        WebDriverWait(self.driver, timeout).until(
            lambda d: d.execute_script("return document.readyState") == 'complete'
        )
        print("ğŸ“„ Page loaded successfully")

    def close_all_popups(self):
        print("ğŸ›¡ï¸ Starting popup defense mechanism")
        self._close_generic_popup(["ä¸‹ä¸€é¡µ", "ç«‹å³ä½“éªŒ", "æˆ‘çŸ¥é“äº†", "å®Œæˆ"])
        self._try_close_popup((By.XPATH, "//div[contains(@class,'banner-close')]"), "Floating ads")
        self._try_close_popup((By.XPATH, "//div[contains(@class,'mask-close')]"), "Final modal")

    def _close_generic_popup(self, texts):
        for text in texts:
            locator = (By.XPATH, f"//button[contains(.,'{text}')]")
            self._try_close_popup(locator, f"Popup: {text}")

    def _try_close_popup(self, locator, name, timeout=8):
        try:
            btn = WebDriverWait(self.driver, timeout).until(EC.element_to_be_clickable(locator))
            self.driver.execute_script("arguments[0].click();", btn)
            print(f"âœ… Closed {name}")
            return True
        except:
            print(f"â³ {name} not found or not clickable")
            return False

    def click_tgzp_tab(self):
        locator = (By.XPATH, "//div[@id='semiTab1' and text()='æŠ•ç¨¿ä½œå“']")
        el = self.wait_for_element_clickable(locator)
        if el:
            el.click()
            print("âœ… ç‚¹å‡»â€œæŠ•ç¨¿ä½œå“â€æˆåŠŸ")

    def click_post_list_tab(self):
        locator = (By.XPATH, "//span[contains(text(),'æŠ•ç¨¿åˆ—è¡¨')]")
        el = self.wait_for_element_clickable(locator)
        if el:
            el.click()
            print("âœ… ç‚¹å‡»â€œæŠ•ç¨¿åˆ—è¡¨â€æˆåŠŸ")

    def input_start_date(self):
        start_date_obj = max(datetime.now() - timedelta(days=90), datetime(2025, 3, 4))
        start_date_str = start_date_obj.strftime("%Y-%m-%d")

        # æ›´ç¨³å¦¥çš„å®šä½æ–¹æ³•ï¼ˆç”¨containsè€Œéç²¾ç¡®åŒ¹é…ï¼‰
        locator = (By.XPATH, "//div[contains(text(),'ç¬”è®°å‘å¸ƒæ—¶é—´')]/../..//input[@placeholder='å¼€å§‹æ—¶é—´']")
        
        try:
            el = WebDriverWait(self.driver, 30).until(EC.presence_of_element_located(locator))
            print(f"ğŸ” å…ƒç´ æ‰¾åˆ°: tag={el.tag_name}, placeholder={el.get_attribute('placeholder')}")

            # ç¡®ä¿å…ƒç´ å¯è§
            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", el)
            time.sleep(1)
            self.driver.execute_script("arguments[0].removeAttribute('readonly')", el)

            actions = ActionChains(self.driver)
            actions.move_to_element(el).click().pause(0.5)
            actions.key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).pause(0.2)
            actions.send_keys(Keys.BACKSPACE).pause(0.2)
            actions.send_keys(start_date_str).pause(0.2)
            actions.send_keys(Keys.ENTER).perform()

            print(f"âœ… ä½¿ç”¨ActionChainsè®¾ç½®å¼€å§‹æ—¥æœŸæˆåŠŸï¼š{start_date_str}")
        except Exception as e:
            print(f"âŒ ä½¿ç”¨ActionChainsè®¾ç½®å¼€å§‹æ—¥æœŸå¤±è´¥ï¼š{start_date_str}ï¼Œé”™è¯¯ï¼š{e}")

    def input_end_date(self):
        end_date_obj = datetime.now() - timedelta(days=1)
        end_date_str = end_date_obj.strftime("%Y-%m-%d")

        locator = (By.XPATH, "//div[contains(text(),'ç¬”è®°å‘å¸ƒæ—¶é—´')]/../..//input[@placeholder='ç»“æŸæ—¶é—´']")
        
        try:
            el = WebDriverWait(self.driver, 30).until(EC.presence_of_element_located(locator))
            print(f"ğŸ” å…ƒç´ æ‰¾åˆ°: tag={el.tag_name}, placeholder={el.get_attribute('placeholder')}")

            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", el)
            time.sleep(1)
            self.driver.execute_script("arguments[0].removeAttribute('readonly')", el)

            actions = ActionChains(self.driver)
            actions.move_to_element(el).click().pause(0.5)
            actions.key_down(Keys.CONTROL).send_keys('a').key_up(Keys.CONTROL).pause(0.2)
            actions.send_keys(Keys.BACKSPACE).pause(0.2)
            actions.send_keys(end_date_str).pause(0.2)
            actions.send_keys(Keys.ENTER).perform()

            print(f"âœ… ä½¿ç”¨ActionChainsè®¾ç½®ç»“æŸæ—¥æœŸæˆåŠŸï¼š{end_date_str}")
        except Exception as e:
            print(f"âŒ ä½¿ç”¨ActionChainsè®¾ç½®ç»“æŸæ—¥æœŸå¤±è´¥ï¼š{end_date_str}ï¼Œé”™è¯¯ï¼š{e}")




    def click_export_data_button(self):
        # æ–° XPathï¼Œæ›´çµæ´»åŒ¹é…å«â€œå¯¼å‡ºæ•°æ®â€çš„æŒ‰é’®
        locator = (By.XPATH, "//button[.//span[contains(.,'å¯¼å‡ºæ•°æ®')]]")
        try:
            self.wait_for_page_ready()
            time.sleep(2)
            button = WebDriverWait(self.driver, 20).until(EC.presence_of_element_located(locator))
            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
            self.driver.execute_script("arguments[0].click();", button)
            print("âœ… ç‚¹å‡»â€œå¯¼å‡ºæ•°æ®â€æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æœªèƒ½æˆåŠŸç‚¹å‡»â€œå¯¼å‡ºæ•°æ®â€æŒ‰é’®ï¼š{e}")

    def wait_for_element_clickable(self, locator, timeout=20):
        try:
            return WebDriverWait(self.driver, timeout).until(EC.element_to_be_clickable(locator))
        except:
            return None

    def merge_and_cleanup_xlsx_files(self):
        """
        æŸ¥æ‰¾ä¸‹è½½ç›®å½•ä¸‹æ‰€æœ‰åŒ…å«å…³é”®è¯çš„ Excel æ–‡ä»¶ï¼Œåˆå¹¶æˆä¸€ä¸ª DataFrameï¼Œ
        åŒæ—¶ä¿å­˜åˆå¹¶åçš„ Excel æ–‡ä»¶å¹¶åˆ é™¤å•ä¸ªæ–‡ä»¶ã€‚
        è¿”å›åˆå¹¶åçš„ DataFrameï¼ˆè‹¥æ²¡æœ‰æ•°æ®åˆ™è¿”å› Noneï¼‰ã€‚
        """
        keyword = "ç¬”è®°åˆ—è¡¨æ˜ç»†è¡¨"
        all_files = glob.glob(os.path.join(self.download_path, f"*{keyword}*.xlsx"))

        if not all_files:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ…å«å…³é”®å­—çš„ Excel æ–‡ä»¶")
            return None

        all_dfs = []
        for file in all_files:
            try:
                # è·³è¿‡ç¬¬ä¸€è¡Œï¼ˆè¯´æ˜æ€§æç¤ºï¼‰ï¼Œä»ç¬¬äºŒè¡Œå¼€å§‹è¯»å–
                df = pd.read_excel(file, skiprows=1)
                df['æ¥æºæ–‡ä»¶'] = os.path.basename(file)
                all_dfs.append(df)
            except Exception as e:
                print(f"âŒ è¯»å–å¤±è´¥ï¼š{file}ï¼Œé”™è¯¯ï¼š{e}")

        if all_dfs:
            result = pd.concat(all_dfs, ignore_index=True)
            if 'é¦–æ¬¡å‘å¸ƒæ—¶é—´' in result.columns:
                try:
                    result['é¦–æ¬¡å‘å¸ƒæ—¶é—´'] = pd.to_datetime(
                        result['é¦–æ¬¡å‘å¸ƒæ—¶é—´'].astype(str),
                        format='%Yå¹´%mæœˆ%dæ—¥%Hæ—¶%Måˆ†%Sç§’',
                        errors='coerce'
                    ).dt.strftime('%Y-%m-%d')
                    print("âœ… æˆåŠŸæ ¼å¼åŒ–â€œé¦–æ¬¡å‘å¸ƒæ—¶é—´â€ä¸º YYYY-MM-DD")
                except Exception as e:
                    print(f"âš ï¸ æ ¼å¼åŒ–â€œé¦–æ¬¡å‘å¸ƒæ—¶é—´â€å¤±è´¥ï¼š{e}")
                    
            output_path = os.path.join(self.download_path, "æ±‡æ€»ç¬”è®°åˆ—è¡¨æ˜ç»†è¡¨.xlsx")
            result.to_excel(output_path, index=False)
            print(f"âœ… æ±‡æ€»æˆåŠŸï¼Œå·²ä¿å­˜ï¼š{output_path}")

            for file in all_files:
                # è·³è¿‡æœ€ç»ˆåˆå¹¶è¾“å‡ºæ–‡ä»¶
                if os.path.basename(file) == os.path.basename(output_path):
                    continue
                try:
                    os.remove(file)
                    print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ–‡ä»¶ï¼š{file}")
                except Exception as e:
                    print(f"âŒ åˆ é™¤å¤±è´¥ï¼š{file}ï¼Œé”™è¯¯ï¼š{e}")
            return result
        else:
            print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œæ±‡æ€»")
            return None

    @classmethod
    def process_all_accounts(cls, cookie_list):
        """
        å¤„ç†å¤šä¸ªè´¦å·ï¼š
        1. æ ¹æ®ä¼ å…¥çš„ cookie_list å’Œå½“å‰è„šæœ¬ç›®å½•ï¼Œä¾æ¬¡åˆå§‹åŒ– Xhs å®ä¾‹å¹¶è¿è¡Œ run() æ–¹æ³•ï¼›
        2. æœ€åè°ƒç”¨ merge_and_cleanup_xlsx_files() åˆå¹¶æ‰€æœ‰ä¸‹è½½çš„ Excel æ–‡ä»¶ï¼Œ
           è¿”å›åˆå¹¶åçš„ DataFrameã€‚
        """
        base_dir = os.path.dirname(os.path.abspath(__file__))
        for cookie_file in cookie_list:
            print(f"\n================ å¤„ç†ï¼š{cookie_file} ================\n")
            full_path = os.path.join(base_dir, cookie_file)
            account = cls(url="https://creator.xiaohongshu.com/statistics/data-analysis", cookies_file=full_path)
            account.run()
        # è°ƒç”¨ä¸€ä¸ªä¸´æ—¶å®ä¾‹æ¥æ‰§è¡Œåˆå¹¶æ–¹æ³•ï¼ˆä¸‹è½½ç›®å½•ä¸ºç»Ÿä¸€é…ç½®ï¼‰
        merged_instance = cls(url="https://creator.xiaohongshu.com/statistics/data-analysis", cookies_file="")  
        df = merged_instance.merge_and_cleanup_xlsx_files()
        return df

# ==========================
# ä¸»ç¨‹åºå…¥å£ï¼ˆè°ƒç”¨ process_all_accounts å³å¯ï¼‰
# ==========================

if __name__ == "__main__":
    # è°ƒç”¨ process_all_accounts æ–¹æ³•å¤„ç†æ‰€æœ‰è´¦å·å¹¶è¿”å›åˆå¹¶åçš„ DataFrame
    final_df = Xhs.process_all_accounts(xhs_cookie_list)
    if final_df is not None:
        print("âœ… æœ€ç»ˆåˆå¹¶çš„ DataFrameï¼š")
        print(final_df.head())
    else:
        print("âš ï¸ æœªèƒ½ç”Ÿæˆåˆå¹¶çš„ DataFrame")
